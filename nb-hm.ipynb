{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as scs\n",
    "from coins import BayesCoin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import nltk\n",
    "from spacy import displacy\n",
    "from sklearn import metrics\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "import unicodedata\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin = BayesCoin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin.choose_coin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3, 0.45, 0.75]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin.coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.3: 0.3333333333333333, 0.45: 0.3333333333333333, 0.75: 0.3333333333333333}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin.flip_coin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin.coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before update: {0.3: 0.3333333333333333, 0.45: 0.3333333333333333, 0.75: 0.3333333333333333}\n",
      "coin: 0.45 flip: 0\n",
      "denominator: [0.2333333333333333, 0.18333333333333335, 0.08333333333333333]\n",
      "data: {0.3: 0.4666666666666667, 0.45: 0.36666666666666675, 0.75: 0.16666666666666669}\n",
      "sum of priors: 1.0000000000000002\n",
      "sum of denominator: 0.49999999999999994\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "coin.update_priors(coin.flip_coin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.3: 0.4666666666666667, 0.45: 0.36666666666666675, 0.75: 0.16666666666666669}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before update: {0.3: 0.6490063467285541, 0.45: 0.35092427227837275, 0.75: 6.938099307317753e-05}\n",
      "coin: 0.45 flip: 1\n",
      "denominator: [0.1947019040185662, 0.15791592252526773, 5.2035744804883145e-05]\n",
      "data: {0.3: 0.552079791437394, 0.45: 0.4477726605286821, 0.75: 0.00014754803392384873}\n",
      "sum of priors: 0.9999999999999999\n",
      "sum of denominator: 0.35266986228863884\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.552079791437394, 0.45: 0.4477726605286821, 0.75: 0.00014754803392384873}\n",
      "coin: 0.45 flip: 1\n",
      "denominator: [0.1656239374312182, 0.20149769723790695, 0.00011066102544288656]\n",
      "data: {0.3: 0.45100591471118817, 0.45: 0.5486927473434832, 0.75: 0.000301337945328547}\n",
      "sum of priors: 0.9999999999999998\n",
      "sum of denominator: 0.36723229569456806\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.45100591471118817, 0.45: 0.5486927473434832, 0.75: 0.000301337945328547}\n",
      "coin: 0.45 flip: 1\n",
      "denominator: [0.13530177441335645, 0.24691173630456742, 0.00022600345899641023]\n",
      "data: {0.3: 0.3537860743928372, 0.45: 0.6456229734418698, 0.75: 0.0005909521652928854}\n",
      "sum of priors: 1.0\n",
      "sum of denominator: 0.3824395141769203\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.3537860743928372, 0.45: 0.6456229734418698, 0.75: 0.0005909521652928854}\n",
      "coin: 0.45 flip: 1\n",
      "denominator: [0.10613582231785117, 0.29053033804884143, 0.0004432141239696641]\n",
      "data: {0.3: 0.26727100676981597, 0.45: 0.7316128923460432, 0.75: 0.0011161008841408906}\n",
      "sum of priors: 1.0\n",
      "sum of denominator: 0.39710937449066225\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.26727100676981597, 0.45: 0.7316128923460432, 0.75: 0.0011161008841408906}\n",
      "coin: 0.45 flip: 1\n",
      "denominator: [0.08018130203094478, 0.32922580155571946, 0.0008370756631056679]\n",
      "data: {0.3: 0.19544775059959554, 0.45: 0.802511816640002, 0.75: 0.002040432760402505}\n",
      "sum of priors: 1.0\n",
      "sum of denominator: 0.41024417924976986\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.19544775059959554, 0.45: 0.802511816640002, 0.75: 0.002040432760402505}\n",
      "coin: 0.45 flip: 0\n",
      "denominator: [0.13681342541971686, 0.44138149915200114, 0.0005101081901006262]\n",
      "data: {0.3: 0.23641305617610905, 0.45: 0.7627054788957803, 0.75: 0.0008814649281105782}\n",
      "sum of priors: 1.0\n",
      "sum of denominator: 0.5787050327618186\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.23641305617610905, 0.45: 0.7627054788957803, 0.75: 0.0008814649281105782}\n",
      "coin: 0.45 flip: 0\n",
      "denominator: [0.16548913932327633, 0.4194880133926792, 0.00022036623202764455]\n",
      "data: {0.3: 0.2827919359958638, 0.45: 0.7168314967342959, 0.75: 0.0003765672698404458}\n",
      "sum of priors: 1.0\n",
      "sum of denominator: 0.5851975189479831\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.2827919359958638, 0.45: 0.7168314967342959, 0.75: 0.0003765672698404458}\n",
      "coin: 0.45 flip: 0\n",
      "denominator: [0.19795435519710464, 0.3942573232038628, 9.414181746011145e-05]\n",
      "data: {0.3: 0.3342097079581356, 0.45: 0.6656313508087267, 0.75: 0.00015894123313762862}\n",
      "sum of priors: 0.9999999999999999\n",
      "sum of denominator: 0.5923058202184276\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.3342097079581356, 0.45: 0.6656313508087267, 0.75: 0.00015894123313762862}\n",
      "coin: 0.45 flip: 0\n",
      "denominator: [0.2339467955706949, 0.36609724294479973, 3.9735308284407156e-05]\n",
      "data: {0.3: 0.3898568929467436, 0.45: 0.6100768907847658, 0.75: 6.621626849066552e-05}\n",
      "sum of priors: 1.0\n",
      "sum of denominator: 0.600083773823779\n",
      "--------------------------------------------------\n",
      "before update: {0.3: 0.3898568929467436, 0.45: 0.6100768907847658, 0.75: 6.621626849066552e-05}\n",
      "coin: 0.45 flip: 1\n",
      "denominator: [0.11695706788402307, 0.27453460085314463, 4.966220136799914e-05]\n",
      "data: {0.3: 0.2987093791699427, 0.45: 0.7011637831313425, 0.75: 0.00012683769871486475}\n",
      "sum of priors: 1.0000000000000002\n",
      "sum of denominator: 0.39154133093853566\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    flip = coin.flip_coin()\n",
    "    coin.update_priors(flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coin.coin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 - Answer: Assumption that data/events are independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 - Answer: Bernoulli is when all values are either 0 or 1, Multinomial is when the data is being counted, Gaussian is for conditional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3 - Answer: No, independence is required for reliable output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('grad.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop('admit')\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e0wrvbu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\e0wrvbu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\e0wrvbu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=21)\n",
    "scalar = StandardScaler().fit(X_train)\n",
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e0wrvbu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7651515151515151"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e0wrvbu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6818181818181818"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954545454545454"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB().fit(X_train, y_train).score(X_test, y_test)\n",
    "# Naive-Bayes Gaussian model performed best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                           1.0   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold     name negativereason_gold  retweet_count  \\\n",
       "0                    NaN  cairdin                 NaN              0   \n",
       "\n",
       "                                  text tweet_coord              tweet_created  \\\n",
       "0  @VirginAmerica What @dhepburn said.         NaN  2015-02-24 11:35:52 -0800   \n",
       "\n",
       "  tweet_location               user_timezone  \n",
       "0            NaN  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('Tweets.csv')\n",
    "tweets.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tweets.pop('airline_sentiment')\n",
    "X = tweets.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn X into a corpus of documents from a series\n",
    "corpus = ' '.join(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize any unicode text within the corpus, replacing all compatibility characters with their equivalents (compatibility decomposition)\n",
    "normalize = (unicodedata.normalize('NFKD', corpus).encode('ASCII', 'ignore').decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21482"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "tokens = list(map(lambda s: word_tokenize(s.lower()), sent_tokenize(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "sw = stopwords.words('english')\n",
    "pt = string.punctuation\n",
    "filtered = [list(filter(lambda token: token not in sw and token not in pt, row)) for row in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_snowball = SnowballStemmer('english')\n",
    "tokens_stemsnowball = [list(map(stemmer_snowball.stem, row)) for row in filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [row + list(map(lambda ng: '-'.join(ng), ngrams(row, 2))) for row in tokens_stemsnowball]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a set of all words in the corpus, creates a lookup from a word to its index/position, initializes an empty numpy matrix to be used to vectorize the documents\n",
    "vocabulary = set()\n",
    "[[vocabulary.add(token) for token in row] for row in documents]\n",
    "vocabulary_lookup = {word: i for i,word in enumerate(vocabulary)}\n",
    "matrix = np.zeros((len(documents), len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count words in each document\n",
    "for doc_id, document in enumerate(documents):\n",
    "    for word in document:\n",
    "        word_id = vocabulary_lookup[word]\n",
    "        matrix[doc_id][word_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 21482 into shape (14640,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-5dac3b9d6266>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# calculate term frequency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14640\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 21482 into shape (14640,1)"
     ]
    }
   ],
   "source": [
    "# calculate term frequency\n",
    "tf = matrix/np.sum(matrix, axis=1).reshape(14640, 1)\n",
    "tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', 'virginamerica', 'what', '@', 'dhepburn', 'said', '.']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
